{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rohwid/GitHub/question-and-answer-chatbot/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the main directory\n",
    "# So, it's executed from main directory\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rohwid/GitHub/question-and-answer-chatbot'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.creds') as f:\n",
    "    os.environ.update(\n",
    "        line.strip().split('=') for line in f\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "PINECONE_INDEX = os.environ.get('PINECONE_INDEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pincone = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pincone.Index(PINECONE_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", dimensions=1536)\n",
    "text_field = \"text\"\n",
    "\n",
    "query = \"What are the specific features or aspects that users appreciate the most in our application?\"\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index, embeddings, text_field, namespace='ns-0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='google_store_review_comments: Awesome UI, best music app out there!', metadata={'author_app_version': '1.1.0.91', 'author_name': 'A Google user', 'pseudo_author_id': '286593453219054880269', 'review_id': '672a155a-e81e-4d28-bdeb-a74c031bc072', 'review_likes': '1', 'review_rating': '5', 'review_timestamp': '2014-05-27 15:17:20', 'row': 3.0, 'source': '672a155a-e81e-4d28-bdeb-a74c031bc072'}),\n",
       " Document(page_content='google_store_review_comments: I enjoy the awesome UI of this app, and it has all the music one can ask for.', metadata={'author_app_version': '1.1.0.91', 'author_name': 'A Google user', 'pseudo_author_id': '234382942865437071667', 'review_id': 'bfa8876b-470e-4640-83a7-77427f7f37e8', 'review_likes': '4', 'review_rating': '5', 'review_timestamp': '2014-05-27 14:36:02', 'row': 1.0, 'source': 'bfa8876b-470e-4640-83a7-77427f7f37e8'}),\n",
       " Document(page_content='google_store_review_comments: Excellent music app', metadata={'author_app_version': '1.1.0.112', 'author_name': 'A Google user', 'pseudo_author_id': '199796654142891370101', 'review_id': '7ded6bd3-37a2-4283-bf22-10286a70f71b', 'review_likes': '1', 'review_rating': '4', 'review_timestamp': '2014-05-27 18:40:42', 'row': 13.0, 'source': '7ded6bd3-37a2-4283-bf22-10286a70f71b'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search(\n",
    "    query,  # our search query\n",
    "    k=3  # return 3 most relevant docs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model_name='gpt-3.5-turbo-instruct', openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "\n",
    "qa_result = qa.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the specific features or aspects that users appreciate the most in our application?',\n",
       " 'result': ' The users appreciate the awesome UI and the variety of music available in the app. They also enjoy the overall experience and the continuous improvement of the app.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot with Chain and Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a prompt to instruct the model to perform as a chatbot also take the summarizaion result previously, take the human input and get the chat history. The chatbot will automatically using chain that connecting or relating the current human input and the previous chat as chat history with `ConversationBufferMemory` or well known as memory. So, `LLMChain` is the library by langchain will use to perform this chain to connects the current chato or human input with the previous chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup prompt to perform as chatbot\n",
    "command = \"\"\"\n",
    "%INSTRUCTIONS:\n",
    "You are very helpful chatbot.\n",
    "\n",
    "%TEXT: {text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=command,\n",
    ")\n",
    "\n",
    "command_prompt = prompt.format(text=qa_result['result'])\n",
    "\n",
    "# Setup prompt to take human imput and chat history.\n",
    "chat = \"\"\"\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "template = command_prompt + chat\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "chat_chain = LLMChain(\n",
    "    llm=OpenAI(model_name='gpt-3.5-turbo-instruct', openai_api_key=OPENAI_API_KEY), \n",
    "    prompt=prompt, \n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs chat by taking the human input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "%INSTRUCTIONS:\n",
      "You are very helpful chatbot.\n",
      "Your goal is only write this piece of text.\n",
      "\n",
      "%TEXT:  The users appreciate the awesome UI and the variety of music available in the app. They also enjoy the overall experience and the continuous improvement of the app.\n",
      "\n",
      "\n",
      "Human: What are the specific features or aspects that users appreciate the most in our application?\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The users appreciate the awesome UI and the variety of music available in the app. They also enjoy the overall experience and the continuous improvement of the app.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_chain.predict(human_input=f'{query}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the memory by asking about the previous chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "%INSTRUCTIONS:\n",
      "You are very helpful chatbot.\n",
      "Your goal is only write this piece of text.\n",
      "\n",
      "%TEXT:  The users appreciate the awesome UI and the variety of music available in the app. They also enjoy the overall experience and the continuous improvement of the app.\n",
      "\n",
      "Human: What are the specific features or aspects that users appreciate the most in our application?\n",
      "AI:  The users appreciate the awesome UI and the variety of music available in the app. They also enjoy the overall experience and the continuous improvement of the app.\n",
      "Human: What was I asked you about?\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' You asked me about the specific features or aspects that users appreciate the most in our application.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_chain.predict(human_input=\"What was I asked you about?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".qna-chatbot-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
